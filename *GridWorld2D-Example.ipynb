{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09d94ef",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "This code is for an the 2D grid world experiment shown in the paper appendix. It is a simple and intuative example that shows what Alg. 1 is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd971dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from tqdm.auto import tqdm\n",
    "import gym\n",
    "\n",
    "import reafference.jnu as J\n",
    "from reafference.data.iterators import gym_iterator\n",
    "\n",
    "\n",
    "# simple grid world environment, see appendix in paper.\n",
    "\n",
    "class Grid2D(gym.Env):\n",
    "    \n",
    "    def __init__(self, n=9, m=2, stochastic_actions=False, noise=None):\n",
    "        super().__init__()\n",
    "        if noise is None:\n",
    "            noise = lambda x: x \n",
    "        self.observation_space = gym.spaces.Box(0,1,shape=(1,n,n))\n",
    "        if not stochastic_actions:\n",
    "            self.action_space = gym.spaces.Discrete(5)\n",
    "            self.actions = lambda a: np.array([[0,0], [0,1], [1,0], [0,-1], [-1,0]], dtype=np.int64)[a]\n",
    "        else: # use stochastic actions\n",
    "            self.action_space = gym.spaces.Discrete(3)\n",
    "            def _actions(a):\n",
    "                assert self.action_space.contains(a)\n",
    "                if a == 0:\n",
    "                    return np.array([0,0])\n",
    "                r = np.random.choice([-1,1])\n",
    "                if a == 1:\n",
    "                    return np.array([0, r])\n",
    "                else:\n",
    "                    return np.array([r, 0])\n",
    "            self.actions = _actions\n",
    "            \n",
    "        self.state = np.zeros((n,n))\n",
    "        self.body = np.ones((m,m)) \n",
    "        self.noise = noise\n",
    "        self.reset()\n",
    "        \n",
    "    @property\n",
    "    def position(self):\n",
    "        return self._position\n",
    "    \n",
    "    @position.setter\n",
    "    def position(self, value):\n",
    "        value = np.array(value).astype(np.int64)\n",
    "        n = self.observation_space.shape[-1]\n",
    "        m = self.body.shape[-1]\n",
    "        self._position = value\n",
    "        self._position[0] = max(0, min(value[0], n - m))\n",
    "        self._position[1] = max(0, min(value[1], n - m))\n",
    "        self.state = np.zeros((n,n))\n",
    "        c1, c2 = self.position\n",
    "        self.state[c1:c1+m,c2:c2+m] = self.body\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.position = self.position + self.actions(action)\n",
    "        self.position = self.noise(self.position)\n",
    "        return self.state[np.newaxis,...].astype(np.float32), 0., False, dict()\n",
    "    \n",
    "    def reset(self):\n",
    "        n = self.observation_space.shape[-1]\n",
    "        m = self.body.shape[-1]\n",
    "        self.state = np.zeros((n,n))\n",
    "        self.position = [(n - m) // 2, (n - m) // 2]\n",
    "        return self.state[np.newaxis,...].astype(np.float32), dict()\n",
    "\n",
    "def all_noise(p):\n",
    "    r = np.random.choice([-1,1])\n",
    "    if np.random.uniform() > 0.5:\n",
    "        return p + np.array([r,0])\n",
    "    else:\n",
    "        return p + np.array([0,r])\n",
    "    \n",
    "def wind_noise(p):\n",
    "    if np.random.uniform() > 0.5:\n",
    "        return p + np.array([np.random.choice([-1,1]),0])\n",
    "    else:\n",
    "        return p\n",
    "    \n",
    "\n",
    "    \n",
    "env = Grid2D(stochastic_actions=False, noise=wind_noise)\n",
    "def episode(env, max_length=100):\n",
    "    state, action, *_ = zip(*gym_iterator(env, max_length=max_length))\n",
    "    state, action = np.stack(state), np.stack(action)\n",
    "    return state[:-1], state[1:], action[:-1]\n",
    "x1, x2, a = episode(env)\n",
    "J.images(x1, on_interact=a, scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65cf594",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Module(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_shape, action_shape, epochs=10):\n",
    "        super().__init__()\n",
    "        self.state_shape = state_shape\n",
    "        self.action_shape = action_shape\n",
    "        s = np.prod(state_shape)\n",
    "        a = np.prod(action_shape)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(s + a, 512), nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512), nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512), nn.LeakyReLU(),\n",
    "            nn.Linear(512, s)\n",
    "        )\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=0.0005)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x, a):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        a = torch.eye(self.action_shape[0], device=a.device)[a.long()]\n",
    "        #print(x.shape, a.shape)\n",
    "        z = torch.cat([x, a], dim=-1)\n",
    "        return self.layers(z).reshape(x.shape[0], *self.state_shape)\n",
    "    \n",
    "    def predict(self, x, a):\n",
    "        pred_total_effect = self.forward(x, a)\n",
    "        noop = torch.zeros_like(a)\n",
    "        pred_exafferent_effect = self.forward(x, noop)\n",
    "        pred_reafferent_effect = pred_total_effect - pred_exafferent_effect.detach()\n",
    "        return pred_total_effect, pred_reafferent_effect, pred_exafferent_effect\n",
    "    \n",
    "    def step(self, x1, x2, a):\n",
    "        self.optim.zero_grad()\n",
    "        pred_total_effect, pred_reafferent_effect, pred_exafferent_effect = self.predict(x1, a)\n",
    "        pred_effect = pred_exafferent_effect + pred_reafferent_effect\n",
    "        total_effect = x2 - x1\n",
    "        loss = self.criterion(pred_effect, total_effect)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.detach()\n",
    "    \n",
    "    def train(self, x1, x2, a, epochs=1000):\n",
    "        pbar = tqdm(range(epochs))\n",
    "        for e in pbar:\n",
    "            x1, x2, a = self.shuffle(x1, x2, a)\n",
    "            loss = self.step(x1, x2, a)\n",
    "            pbar.set_description(f\"loss: {loss.item() :.6f}\")\n",
    "    \n",
    "    def shuffle(self, *x):\n",
    "        indx = torch.randperm(x[0].shape[0])\n",
    "        return [z[indx] for z in x]\n",
    "\n",
    "x0, x1, a = zip(*[episode(env, max_length=100) for i in range(100)])\n",
    "x0, x1, a = np.concatenate(x0), np.concatenate(x1), np.concatenate(a)\n",
    "print(x0.shape, a.shape)\n",
    "x0, x1, a = torch.from_numpy(x0).cuda(), torch.from_numpy(x1).cuda(), torch.from_numpy(a).cuda()\n",
    "\n",
    "model = Module(state_shape=env.observation_space.shape, action_shape=(env.action_space.n,)).cuda()\n",
    "model.train(x0, x1, a, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391ad3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torchvision.io\n",
    "def show(action, n = 100):\n",
    "    _x, _a = x0[:n], a[:n]\n",
    "    p = 2\n",
    "    t, re, ex = model.predict(_x, torch.zeros_like(_a) + action) \n",
    "    t = torchvision.transforms.functional.resize(t, (90, 90), interpolation=0)\n",
    "    re = torchvision.transforms.functional.resize(re, (90, 90), interpolation=0)\n",
    "    ex = torchvision.transforms.functional.resize(ex, (90, 90), interpolation=0)\n",
    "    _x = torchvision.transforms.functional.resize(_x, (90, 90), interpolation=0)\n",
    "    b = torch.ones(_x.shape[0], 1, _x.shape[2], p).cuda()\n",
    "    eff = (torch.cat([b,t,b,re,b,ex], dim=-1) + 1) / 2\n",
    "    imgs = 1 - torch.clip(torch.cat([_x, eff], dim=-1), 0, 1)\n",
    "    b = torch.zeros(imgs.shape[0], imgs.shape[1], imgs.shape[2] + p * 2, imgs.shape[3] + p * 2)\n",
    "    b[:,:,p:-p,p:-p] = imgs\n",
    "    imgs = b\n",
    "    J.images(imgs)\n",
    "    return imgs[18]\n",
    "   \n",
    "imgs = []\n",
    "for _a in range(env.action_space.n):\n",
    "    print(\"ACTION:\", _a)\n",
    "    img = show(_a)\n",
    "    #torchvision.io.write_png((img.cpu() * 255).byte(), f\"./media/World2D-Action-{_a}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324e85e",
   "metadata": {},
   "source": [
    "# Long term effects\n",
    "\n",
    "Below shows how to compute the long term effects from single-step estimates. In this instance, there are only exafferent effects, unless one specifies more than one action in the forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d01993",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = env.reset()[0]\n",
    "a = np.zeros(10)\n",
    "\n",
    "def forecast(model, x0, an):\n",
    "    assert x0.shape[0] == a.shape[1]\n",
    "    x0, an = x0.cuda(), an.cuda()\n",
    "    def _forecast(x0, an):\n",
    "        for a in an:\n",
    "            yield x0, a\n",
    "            t, re, ex = model.predict(x0, a)\n",
    "            x0 = x0 + t\n",
    "        #yield x0, torch.zeros_like(a)\n",
    "    X, A = zip(*_forecast(x0, an))\n",
    "    return torch.cat(X).clip(0,1), torch.cat(A)\n",
    "      \n",
    "x0, a = torch.from_numpy(x0).unsqueeze(0), torch.from_numpy(a).unsqueeze(1)\n",
    "\n",
    "X0, A = forecast(model, x0, a)\n",
    "a[0] = 1\n",
    "X, A = forecast(model, x0, a)\n",
    "\n",
    "J.images(torch.cat([X0, X, (X - X0 + 1) / 2], dim=-1), on_interact=A,scale=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9e2c6",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reaff",
   "language": "python",
   "name": "reaff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
